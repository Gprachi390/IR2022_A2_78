{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UPxHg3D9eYV",
        "outputId": "11b6a552-2bef-4900-d00f-3e33e12fae72"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABdsfSap4w4P",
        "outputId": "b88e676a-19e5-438c-db0d-02e27821cca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#Importing libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "import nltk\n",
        "import operator\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from random import shuffle\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lema = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the file\n",
        "file = \"/content/drive/MyDrive/20_newsgroups.zip\" \n",
        "#Defining labels\n",
        "label = ['comp.graphics', 'rec.sport.hockey', 'sci.med', 'sci.space', 'talk.politics.misc']  \n",
        "# opening the zip file in read mode\n",
        "with ZipFile(file, 'r') as zip:\n",
        "    zip.printdir()\n",
        "    zip.extractall()"
      ],
      "metadata": {
        "id": "VJMrOuNg9eaa"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = []\n",
        "file_name=\"20_newsgroups\"\n",
        "folders = os.listdir(file_name)\n",
        "file_list = []\n",
        "count = 0\n",
        "\n",
        "for l in label:\n",
        "  for root, _, files in os.walk(str(os.getcwd())+'/'+file_name+'/'+str(l)):\n",
        "      for file in files:\n",
        "          file_path = os.path.join(root, file)\n",
        "          file_list.append(file_path)\n",
        "          classes.append(l)\n",
        "        \n",
        "len(file_list),len(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2X5Yoh99ecs",
        "outputId": "7f580850-a118-4adf-824c-f2cf2c3f711a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 5000)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ln = len(string.punctuation)\n",
        "#Cleaning the data\n",
        "def pre_process(content):\n",
        "  #Convert the text to lower case\n",
        "  content = content.lower()\n",
        "  #Remove punctuation marks from tokens\n",
        "  content = content.translate(str.maketrans(string.punctuation, \" \"*ln,''))\n",
        "  #Perform word tokenization\n",
        "  ctokens = word_tokenize(content)\n",
        "  #Remove stopwords from tokens and do lemmatization\n",
        "  #Checking length, if length = 1\n",
        "  ctokens = [lema.lemmatize(s) for s in ctokens if s not in stopwords.words('english') and s.isalpha and len(s)>1]\n",
        "  return ctokens"
      ],
      "metadata": {
        "id": "jgsqmoPk9ee0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJPJsmglEHPv",
        "outputId": "8ae3a64e-b1fe-4110-8997-2459df995bde"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#performing preprocessing and saving the data\n",
        "docs = []\n",
        "# word_list={}\n",
        "for path in file_list:\n",
        "  file = open(path, 'r', encoding='cp1250')\n",
        "  text = file.read().strip()\n",
        "  x=pre_process(text)\n",
        "  file.close()\n",
        "  docs.append(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JpQDfqSV9ehI",
        "outputId": "e9495a64-c10b-40d0-addd-eacf81644b2d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'docs_pd = pd.DataFrame([docs,classes]).T\\nprint(docs_pd)\\ndocs_pd[0] = pre_process(docs_pd[0])\\ndocs_pd.to_csv(\"docs_pd.csv\")\\ndocs_pd.to_pickle(\"docs_pd\")\\ndocs_pd'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting the dataframes to csv \n",
        "docs_pd = pd.DataFrame([docs,classes]).T\n",
        "docs_pd.to_pickle(\"docs_pd\")\n",
        "docs_pd.to_csv(\"docs_pd.csv\")\n",
        "docs_pd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ZBHJu_1vKQL5",
        "outputId": "d62ee9ed-e844-4330-80f2-2e5263478fd4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                      0                   1\n",
              "0     [xref, cantaloupe, srv, c, cmu, edu, comp, gra...       comp.graphics\n",
              "1     [xref, cantaloupe, srv, c, cmu, edu, comp, gra...       comp.graphics\n",
              "2     [newsgroups, comp, graphic, path, cantaloupe, ...       comp.graphics\n",
              "3     [newsgroups, comp, graphic, path, cantaloupe, ...       comp.graphics\n",
              "4     [xref, cantaloupe, srv, c, cmu, edu, comp, gra...       comp.graphics\n",
              "...                                                 ...                 ...\n",
              "4995  [xref, cantaloupe, srv, c, cmu, edu, talk, pol...  talk.politics.misc\n",
              "4996  [xref, cantaloupe, srv, c, cmu, edu, talk, pol...  talk.politics.misc\n",
              "4997  [xref, cantaloupe, srv, c, cmu, edu, alt, fan,...  talk.politics.misc\n",
              "4998  [xref, cantaloupe, srv, c, cmu, edu, sci, skep...  talk.politics.misc\n",
              "4999  [xref, cantaloupe, srv, c, cmu, edu, talk, pol...  talk.politics.misc\n",
              "\n",
              "[5000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-852513fb-314a-42bc-bc59-19d8ec2f22cf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[xref, cantaloupe, srv, c, cmu, edu, comp, gra...</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[xref, cantaloupe, srv, c, cmu, edu, comp, gra...</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[newsgroups, comp, graphic, path, cantaloupe, ...</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[newsgroups, comp, graphic, path, cantaloupe, ...</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[xref, cantaloupe, srv, c, cmu, edu, comp, gra...</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>[xref, cantaloupe, srv, c, cmu, edu, talk, pol...</td>\n",
              "      <td>talk.politics.misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>[xref, cantaloupe, srv, c, cmu, edu, talk, pol...</td>\n",
              "      <td>talk.politics.misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>[xref, cantaloupe, srv, c, cmu, edu, alt, fan,...</td>\n",
              "      <td>talk.politics.misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>[xref, cantaloupe, srv, c, cmu, edu, sci, skep...</td>\n",
              "      <td>talk.politics.misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>[xref, cantaloupe, srv, c, cmu, edu, talk, pol...</td>\n",
              "      <td>talk.politics.misc</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-852513fb-314a-42bc-bc59-19d8ec2f22cf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-852513fb-314a-42bc-bc59-19d8ec2f22cf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-852513fb-314a-42bc-bc59-19d8ec2f22cf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs_pd=pd.read_pickle('/content/docs_pd')"
      ],
      "metadata": {
        "id": "SUmobg8fCYbi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Naive Bayes Model with TF-ICF**"
      ],
      "metadata": {
        "id": "KFk6zy_lDEkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Class for implementing Naive Bayes algorithm with TF-ICF\n",
        "class NaiveBayes_tf_icf:\n",
        "\n",
        "  #Function to predict\n",
        "  def predict(self,X_test):\n",
        "    predc = []\n",
        "    for i in range(len(X_test)):\n",
        "        classes_words_probability = []\n",
        "        for l in label:\n",
        "            words_probability = 0\n",
        "            for word in X_test[i]:\n",
        "                fr, cn = self._word_freq(word, l)\n",
        "                pp = (fr+1) /(cn+len(self._unique_words))\n",
        "                words_probability += np.log(pp)\n",
        "            classes_words_probability.append(words_probability)\n",
        "        predc.append(label[np.argmax(classes_words_probability)])\n",
        "    return predc\n",
        "\n",
        "  #Function to compute confusion matrix\n",
        "  def confusion_matrix(self, ypred, ytest):\n",
        "    matrix= np.zeros((len(label), len(label))).astype(int)\n",
        "    for i in range(len(ypred)):\n",
        "        matrix[label.index(ypred[i])][label.index(ytest[i])]+= 1\n",
        "    return matrix\n",
        "  \n",
        "\n",
        "  #Function to compute accuracy\n",
        "  def calculate_accuracy(self, ypred, ytest):\n",
        "    return len([1 for i in range(len(ypred)) if ypred[i] == ytest[i]])/len(ypred)\n",
        "\n",
        "\n",
        "  #Function to compute word frequency\n",
        "  def _word_freq(self, word, label):\n",
        "    try:\n",
        "        return self._word_freq_per_class[label, word], self._number_words_perclass[label]\n",
        "    except:\n",
        "        return 0, self._number_words_perclass[label]\n",
        "\n",
        "  #Calculate tf-icf\n",
        "  def _calculate_tf_icf(self):\n",
        "    self._tf_icf = {}\n",
        "    c = Counter(self._word_list)\n",
        "    for i in set(self._word_list):\n",
        "      tf = c[i]\n",
        "      icf = np.log(len(self._m_dict)/self._class_word[i]+1)\n",
        "      self._tf_icf[i] = tf*icf\n",
        "\n",
        "  #Function to fit the data\n",
        "  def fit(self,X_train,y_train, k):\n",
        "    words = X_train\n",
        "    self._N = len(words)\n",
        "    classes = y_train\n",
        "    self._m_dict = {}\n",
        "    for i in range(self._N):\n",
        "      if classes[i] in self._m_dict.keys():\n",
        "          self._m_dict[classes[i]] = self._m_dict[classes[i]] + words[i]\n",
        "      else:\n",
        "          self._m_dict[classes[i]] = words[i]\n",
        "\n",
        "    #Listing words containing multiple occurence of same word\n",
        "    self._word_list = []\n",
        "    for i in self._m_dict:\n",
        "        self._word_list = self._word_list + self._m_dict[i]\n",
        "\n",
        "    #Count of word per class\n",
        "    self._class_word = {}\n",
        "    for i in self._m_dict:\n",
        "      l=self._m_dict[i]\n",
        "      for j in set(l):\n",
        "        if j not in self._class_word.keys():\n",
        "          self._class_word[j] = 1\n",
        "        else:\n",
        "          self._class_word[j] += 1\n",
        "    self._calculate_tf_icf()\n",
        "    sorted_x = sorted(self._tf_icf.items(), key = operator.itemgetter(1), reverse=True)\n",
        "\n",
        "\n",
        "    #considering top k features \n",
        "    self._unique_words = [i[0] for i in sorted_x[:int(len(sorted_x)*k)]]  \n",
        "    self._word_freq_per_class = {}\n",
        "    self._number_words_perclass = {}\n",
        "    for i in label:\n",
        "        freq_list= Counter(self._m_dict[i])\n",
        "        for j in self._unique_words:\n",
        "            self._word_freq_per_class[i,j] = freq_list[j]\n",
        "            if i in self._number_words_perclass.keys():\n",
        "                self._number_words_perclass[i] = self._number_words_perclass[i] +freq_list[j]\n",
        "            else:\n",
        "                self._number_words_perclass[i] = freq_list[j]\n",
        "    self._freq_train = {}\n",
        "    for i in y_train:\n",
        "      if i not in self._freq_train.keys():\n",
        "        self._freq_train[i] = 1\n",
        "      else:\n",
        "        self._freq_train[i] += 1"
      ],
      "metadata": {
        "id": "PWKkaAD8CYgU"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#50:50, 70:30, and 80:20 training and testing split ratios\n",
        "ratio = [0.5,0.7,0.8]\n",
        "naive_tf_dict = []\n",
        "\n",
        "for i in range(3):\n",
        "  train = docs_pd.sample(frac=ratio[i],random_state=42)\n",
        "  xtrain, ytrain = train[0].tolist(),train[1].tolist()\n",
        "  test = docs_pd.sample(frac=1,random_state=42).drop(train.index)\n",
        "\n",
        "  xtest,ytest = test[0].tolist(),test[1].tolist()\n",
        "  nb = NaiveBayes_tf_icf()\n",
        "  #Fitting the xtrain and ytrain\n",
        "  #Taking k as 500\n",
        "  k = 500\n",
        "  nb.fit(xtrain, ytrain, k)\n",
        "  ypred = nb.predict(xtest)\n",
        "\n",
        "  r = int(ratio[i]*100)\n",
        "  accuracy = nb.calculate_accuracy(ypred, ytest)*100\n",
        "  naive_tf_dict.append(accuracy)\n",
        "\n",
        "  print(\"At ratio {}:{}\".format(r,100-r))\n",
        "  print(\"\\n\")\n",
        "  print(\"Confusion Matrix is given by: \\n\",nb.confusion_matrix(ypred,ytest))\n",
        "  print(\"\\n\")\n",
        "  print(\"Accuracy is {:.2f} \\n\".format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hldDJOSvCYjb",
        "outputId": "8d3e7702-5837-47ce-ee32-88244869bab3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At ratio 50:50\n",
            "\n",
            "\n",
            "Confusion Matrix is given by: \n",
            " [[491   4  10  11   1]\n",
            " [  1 478   2   1   0]\n",
            " [  0   0 465   4   0]\n",
            " [  2   0   8 503   4]\n",
            " [  0   2   7   3 503]]\n",
            "\n",
            "\n",
            "Accuracy is 97.60 \n",
            "\n",
            "At ratio 70:30\n",
            "\n",
            "\n",
            "Confusion Matrix is given by: \n",
            " [[299   1   4   5   0]\n",
            " [  0 277   0   1   0]\n",
            " [  2   0 291   3   0]\n",
            " [  1   0   3 302   4]\n",
            " [  0   0   3   0 304]]\n",
            "\n",
            "\n",
            "Accuracy is 98.20 \n",
            "\n",
            "At ratio 80:20\n",
            "\n",
            "\n",
            "Confusion Matrix is given by: \n",
            " [[189   1   4   2   0]\n",
            " [  0 190   0   0   0]\n",
            " [  0   0 204   2   0]\n",
            " [  0   0   2 200   3]\n",
            " [  0   0   3   0 200]]\n",
            "\n",
            "\n",
            "Accuracy is 98.30 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "U66x-xe6LKp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NYWwwBxBLKsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xx6UQ3ihLKu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9sEQNLvnLKyP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}